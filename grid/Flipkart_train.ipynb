{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfIrcdBgB84D"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install PyPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS1vcldVAdtm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import PyPDF2\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpZaNERgHTiB"
      },
      "source": [
        "# --- File Extraction Functions ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okmxSnNAGfNH"
      },
      "outputs": [],
      "source": [
        "def extract_from_pdf(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfFileReader(file)\n",
        "        text = \" \".join([reader.getPage(i).extractText() for i in range(reader.numPages)])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZVDAsX0Gh6u"
      },
      "outputs": [],
      "source": [
        "def extract_words_from_csv(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.astype(str)\n",
        "    # Splitting each row's entry by spaces to get individual words\n",
        "    return [entry.split() for entry in df.values.flatten()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EIltdUqGkC3"
      },
      "outputs": [],
      "source": [
        "def extract_from_txt(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5CTvi8zHMkQ"
      },
      "outputs": [],
      "source": [
        "def extract_data(file_path, file_format):\n",
        "    if file_format == 'pdf':\n",
        "        return extract_from_pdf(file_path)\n",
        "    elif file_format == 'csv':\n",
        "        return extract_words_from_csv(file_path)\n",
        "    elif file_format == 'txt':\n",
        "        return extract_from_txt(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOFNuG3THRLX"
      },
      "source": [
        "# --- LLM Functions ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcCOuyWUHPEm"
      },
      "outputs": [],
      "source": [
        "def text_to_embedding(text):\n",
        "    # Set the padding token if it's not already set\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Tokenize the text with a higher max_length and generate the attention mask\n",
        "    tokens = tokenizer.encode_plus(text, max_length=512, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
        "    input_ids = tokens['input_ids']\n",
        "    attention_mask = tokens['attention_mask']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Use the embedding of the [CLS] token\n",
        "    return outputs[0][:, 0, :]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaD3B1h9HVeW"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(a, b):\n",
        "    return torch.nn.functional.cosine_similarity(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faKqb4RiHuL-"
      },
      "outputs": [],
      "source": [
        "policy_data = extract_data('policies_questions.csv', 'csv')\n",
        "logs_data = extract_data('logs.csv', 'csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvzw9JEfKPzV"
      },
      "outputs": [],
      "source": [
        "def extract_relevant_policy_by_embedding(log_embedding, policy_data):\n",
        "    # We assume that policy_data is a list of individual policies\n",
        "    best_score = -float('inf')\n",
        "    best_policy = \"\"\n",
        "\n",
        "    for policy in policy_data:\n",
        "\n",
        "        policy_embedding = text_to_embedding(policy)\n",
        "        similarity_score = cosine_similarity(log_embedding, policy_embedding)\n",
        "\n",
        "        if similarity_score > best_score:\n",
        "            best_score = similarity_score\n",
        "            best_policy = policy\n",
        "\n",
        "    return best_policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EccL0_ZhH2_1"
      },
      "outputs": [],
      "source": [
        "remediation_statements = {}\n",
        "for log in non_compliant_logs:\n",
        "    remediation_statements[log] = generate_remediation(log)\n",
        "print(remediation_statements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUZ5fouKlBit"
      },
      "outputs": [],
      "source": [
        "policy_data_list = extract_data('policies_questions.csv','csv')\n",
        "logs_list = extract_data('logs.csv' ,'csv')\n",
        "# Drop rows containing 'nan' values\n",
        "policy_data_list = [policy_data for policy_data in policy_data_list if policy_data != ['nan']]\n",
        "logs_list = [log_data for log_data in logs_list if log_data != ['nan']]\n",
        "print(policy_data_list)\n",
        "print(logs_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFY5lnaFk-tk"
      },
      "outputs": [],
      "source": [
        "policy_data_list = extract_data('policies_questions.csv','csv')\n",
        "logs_list = extract_data('logs.csv' ,'csv')\n",
        "# Drop rows containing 'nan' values\n",
        "policy_data_list = [policy_data for policy_data in policy_data_list if policy_data != ['nan']]\n",
        "logs_list = [log_data for log_data in logs_list if log_data != ['nan']]\n",
        "print(policy_data_list)\n",
        "print(logs_list)\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "config = BertConfig.from_pretrained(model_name, num_labels=2)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, config=config)\n",
        "\n",
        "\n",
        "# Create an empty list to store results\n",
        "results = []\n",
        "i = 0\n",
        "\n",
        "joined_logs_list = []\n",
        "for log in logs_list:\n",
        "  one_log = ' '.join(log)\n",
        "  joined_logs_list.append(one_log)\n",
        "\n",
        "joined_policy_list = []\n",
        "for pol in policy_data_list:\n",
        "  one_pol = ' '.join(pol)\n",
        "  joined_policy_list.append(one_pol)\n",
        "\n",
        "for log_data in joined_logs_list:\n",
        "  log_embedding = text_to_embedding(log)\n",
        "  relevant_policy = extract_relevant_policy_by_embedding(log_embedding, joined_policy_list)\n",
        "  question = \"Is this compliant with the policy?\"\n",
        "  for policy_data in relevant_policy:\n",
        "\n",
        "        # Combine policy and log as text\n",
        "        text = f\"Policy: {policy}\\nLog: {log}\\nQuestion: {question}\"\n",
        "        # print(policy)\n",
        "        # print(log)\n",
        "        i += 1\n",
        "        print(i)\n",
        "        # Tokenize and classify\n",
        "        inputs = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt', padding='max_length', max_length=128, truncation=True)\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        # Get the predicted label and confidence score\n",
        "        predicted_label = torch.argmax(probs).item()\n",
        "        confidence_score = probs[0][predicted_label].item()\n",
        "\n",
        "        # Map predicted label to \"Yes\" or \"No\"\n",
        "        answer = \"Yes\" if predicted_label == 1 else \"No\"\n",
        "\n",
        "        # Append the result to the list\n",
        "        results.append({\"Policy\": policy, \"Log\": log, \"Answer\": answer, \"Confidence Score\": confidence_score})\n",
        "\n",
        "# Create a DataFrame from the results list\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Print the results DataFrame\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbWXtJ2NmiYm"
      },
      "outputs": [],
      "source": [
        "excel_file_path = 'results.xlsx'\n",
        "results_df.to_excel(excel_file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDyqlGF6Tqqr"
      },
      "outputs": [],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDjVwiw4kL2-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Read the CSV file\n",
        "csv_file_path = 'labeled.csv'\n",
        "df = pd.read_csv(csv_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5AwO6XLDwTf"
      },
      "outputs": [],
      "source": [
        "out_1 = df[df.Label == 1]\n",
        "out_0 = df[df.Label == 0]\n",
        "\n",
        "out_0 = out_0.sample(n=240,replace = True)\n",
        "\n",
        "df = pd.concat([out_1, out_0], axis=0).sample(frac=1).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX3CG9XxmBCZ"
      },
      "outputs": [],
      "source": [
        "# Extract data from specific columns into lists\n",
        "policy_list = df['Policy'].tolist()\n",
        "log_list = df['Log'].tolist()\n",
        "labels_list = df['Label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AJ3jt9-pPvg"
      },
      "outputs": [],
      "source": [
        "text_list = []\n",
        "questions = []\n",
        "\n",
        "for policy_data in policy_list:\n",
        "    # Remove extra spaces within policy_data\n",
        "    cleaned_policy_data = ' '.join(policy_data.split())  # This will remove extra spaces\n",
        "    policy = cleaned_policy_data\n",
        "\n",
        "    for log_data in log_list:\n",
        "        cleaned_log = ' '.join(log_data.split())  # Join the words to form the log text\n",
        "        log = cleaned_log\n",
        "        question = 'Is the log compliant with the policy?'\n",
        "\n",
        "        # Combine policy and log as text\n",
        "        combined_text = f\"Policy: {policy}\\nLog: {log}\"\n",
        "        text_list.append(combined_text)  # Append the combined text to the list\n",
        "        questions.append(question)\n",
        "print(len(text_list))\n",
        "print(len(questions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlijPtIo7cea"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCQDuLFqDX-o"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhyqZK0iilMx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "config = BertConfig.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "labels = labels_list\n",
        "# Combine policy and log as text\n",
        "policy_text = ' '.join(policy_list[0])  # Join the words to form the policy text\n",
        "\n",
        "# Split data into train and validation sets\n",
        "log_texts_train, log_texts_val, labels_train, labels_val = train_test_split(log_list[:], labels[:], test_size=0.2, random_state=42)\n",
        "\n",
        "log_texts_train =log_texts_train + log_texts_val\n",
        "labels_train = labels_train + labels_val\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frptb-JWHONj"
      },
      "outputs": [],
      "source": [
        "labels_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KUGid4YHLjn"
      },
      "outputs": [],
      "source": [
        "# Grid of hyperparameters\n",
        "learning_rates = [1e-4]\n",
        "batch_sizes = [40]\n",
        "\n",
        "# Hyperparameter tuning loop\n",
        "best_accuracy = 0.0\n",
        "best_hyperparameters = {}\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        model = BertForSequenceClassification.from_pretrained(model_name, config=config)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "        loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        # Create data loaders\n",
        "        train_inputs = tokenizer(log_texts_train, add_special_tokens=True, padding=True, truncation=True, return_tensors='pt')\n",
        "        val_inputs = tokenizer(log_texts_val, add_special_tokens=True, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "        train_labels = torch.tensor(labels_train)\n",
        "        val_labels = torch.tensor(labels_val)\n",
        "\n",
        "        train_data = torch.utils.data.TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
        "        val_data = torch.utils.data.TensorDataset(val_inputs['input_ids'], val_inputs['attention_mask'], val_labels)\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "\n",
        "        # Training loop\n",
        "        num_epochs = 20\n",
        "        for epoch in tqdm(range(num_epochs)):\n",
        "            # model = model.to('cuda')\n",
        "            model.train()\n",
        "            for batch in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                input_ids, attention_mask, labels = batch\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "                loss = loss_fn(logits, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                print(loss)\n",
        "\n",
        "            # Validation\n",
        "            model.eval()\n",
        "            correct_predictions = 0\n",
        "            total_samples = 0\n",
        "            with torch.no_grad():\n",
        "                for batch in val_loader:\n",
        "                    input_ids, attention_mask, labels = batch\n",
        "                    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                    logits = outputs.logits\n",
        "                    _, predicted = torch.max(logits, dim=1)\n",
        "                    print(predicted,labels)\n",
        "                    correct_predictions += (predicted == labels).sum().item()\n",
        "                    total_samples += labels.size(0)\n",
        "\n",
        "            accuracy = correct_predictions / total_samples\n",
        "            print(f\"Learning Rate: {learning_rate} - Batch Size: {batch_size} - Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "            # Keep track of best hyperparameters\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_hyperparameters = {\"Learning Rate\": learning_rate, \"Batch Size\": batch_size}\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no5M31i94RE4"
      },
      "outputs": [],
      "source": [
        "best_model_dir = \"best_bert_model\"\n",
        "model.save_pretrained(best_model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfRua3n6l3e6"
      },
      "outputs": [],
      "source": [
        "newpolicy_data_list = extract_data('policies_questions.csv','csv')\n",
        "newlogs_list = extract_data('logs.csv' ,'csv')\n",
        "\n",
        "# Drop rows containing 'nan' values\n",
        "newpolicy_data_list = [policy_data for policy_data in newpolicy_data_list if policy_data != ['nan']]\n",
        "newlogs_list = [log_data for log_data in newlogs_list if log_data != ['nan']]\n",
        "print(newpolicy_data_list)\n",
        "print(newlogs_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxqMMkWZlhSK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "config = BertConfig.from_pretrained(model_name, num_labels=2)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "best_model_dir = \"best_bert_model\"  # Change this to the directory where you saved your best model\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(best_model_dir, config=config)\n",
        "\n",
        "# Assuming policy_list and log_list contain your data\n",
        "question = 'Is the log compliant with the policy?'\n",
        "results = []  # To store the results\n",
        "i = 0\n",
        "# Loop through policy and log pairs\n",
        "for policy in newpolicy_data_list:\n",
        "  for log in  newlogs_list:\n",
        "    input_text = f\"Policy: {policy}\\nLog: {log}\\nQuestion: {question}\\n\"\n",
        "    inputs = tokenizer(input_text, add_special_tokens=True, padding=True, truncation=True, return_tensors='pt')\n",
        "    i+=1\n",
        "    print(i)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = loaded_model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_label = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    results.append({\"Policy\": policy, \"Log\": log, \"Predicted_Label\": predicted_label})\n",
        "\n",
        "# Create a DataFrame from the results\n",
        "output_df = pd.DataFrame(results)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(output_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLrKi88Rltcm"
      },
      "outputs": [],
      "source": [
        "excel_file_path = 'results.xlsx'\n",
        "output_df.to_excel(excel_file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_jpJZ8QsPK9"
      },
      "outputs": [],
      "source": [
        "best_model_dir = \"best_bert_model\"\n",
        "model.save_pretrained(best_model_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORqtrdOcxSyA"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"best_bert_model\", \"zip\", \"best_bert_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtVHmK9AxVVg"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"best_bert_model.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fyiB27YpxX2h"
      },
      "outputs": [],
      "source": [
        "# Model Declaration\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, config=config)\n",
        "\n",
        "# hyperparameters\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "learning_rates = 1e-4\n",
        "batch_sizes = 40\n",
        "num_epochs = 20\n",
        "\n",
        "# Create data loaders\n",
        "train_inputs = tokenizer(log_texts_train, add_special_tokens=True, padding=True, truncation=True, return_tensors='pt')\n",
        "val_inputs = tokenizer(log_texts_val, add_special_tokens=True, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "train_labels = torch.tensor(labels_train)\n",
        "val_labels = torch.tensor(labels_val)\n",
        "\n",
        "train_data = torch.utils.data.TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
        "val_data = torch.utils.data.TensorDataset(val_inputs['input_ids'], val_inputs['attention_mask'], val_labels)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "\n",
        "# Training loop\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    # model = model.to('cuda')\n",
        "    model.train()\n",
        "    for batch in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        loss = loss_fn(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            _, predicted = torch.max(logits, dim=1)\n",
        "            print(predicted,labels)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    print(f\"Learning Rate: {learning_rate} - Batch Size: {batch_size} - Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}